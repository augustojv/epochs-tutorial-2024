<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Agile Software-Hardware Co-Design of AI-Centric Heterogeneous SoCs</title>

    <!-- css -->
    <link rel="stylesheet" href="bower_components/bootstrap/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="bower_components/ionicons/css/ionicons.min.css">
    <link rel="stylesheet" href="assets/css/main.css">
</head>
<body data-spy="scroll" data-target="#site-nav">
    <nav id="site-nav" class="navbar navbar-fixed-top navbar-custom">
        <div class="container">
            <div class="navbar-header">

                <!-- logo -->
                <div class="site-branding">
                    <a class="logo" href="index.html">
                        
                        <!-- logo image  -->
                        <!-- <img src="assets/images/logo.png" alt="Logo"> -->
                        EPOCHS
                    </a>
                </div>

                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-items" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>

            </div><!-- /.navbar-header -->

            <div class="collapse navbar-collapse" id="navbar-items">
                <ul class="nav navbar-nav navbar-right">

                    <!-- navigation menu -->
                    <li class="active"><a data-scroll href="#about">About</a></li>
                    <li><a data-scroll href="#speakers">Speakers</a></li>         
                    <li><a data-scroll href="#program">Program</a></li>
                    <li><a data-scroll href="#org">Organizers</a></li>
                
                </ul>
            </div>
        </div><!-- /.container -->
    </nav>

    <header id="site-header" class="site-header valign-center"> 
        <div class="intro">

            <p>June 29<sup>th</sup> 2024, Buenos Aires, Argentina</p>

            <h1>EPOCHS 2024 Tutorial</h1>            
			
			<h2 style="color: #FF7A59"><strong>Agile Software-Hardware Co-Design of AI-Centric Heterogeneous SoCs</strong></h2>
            
            <p>In conjunction with the 51<sup>st</sup> International Symposium<br>
                on Computer Architecture (ISCA 2024)</p>
            
            <a class="btn btn-white" data-scroll href="#registration">Register Now</a>
        
        </div>
    </header>

    <section id="about" class="section about">
        <div class="container">
            <div class="row">
                <div class="col-sm-6">

                    <h3 class="section-title">About</h3>
                    
                    <p>
					Intelligent edge systems constitute a key growth segment within the cloud-backed cognitive IoT marketplace. The EPOCHS
					("Efficient Programmability of Cognitive Heterogeneous Systems") research project at IBM (with collaborative university
					partners) is driven by the specific edge application domain of connected autonomous vehicles. An adjacent domain application
					considered was extended reality (XR), modeled by the ILLIXR project at UIUC. Our team has developed leading edge methodologies
					for agile software-hardware co-design of heterogeneous SoCs to support the target application domains. As part of this project,
					we have successfully taped out two functional EPOCHS chips in 12 nm technology and have demonstrated full-stack solutions using
					FPGA and ASIC versions of the chipset. Specific use cases that have been illustrated in the context of our active technology
					transition phase are: (a) collaborative perception, involving a pair of communicating autonomous vehicles; (b) detecting hazards
					while scanning for objects and vehicles during autonomous navigation; (c) sentiment analysis of human-expressed conversations or
					commands (using an NLP algorithm).
					</p>
					<p>
					In this tutorial, we summarize the key innovations and open-source tools-driven agile methodology derived from this 5-year DARPA-
					sponsored project (2018-2023) that is now transitioning into commercially deployable solutions in partnership with clients. In
					particular, we will cover the following aspects of the overall topic area in considerable detail: (a) the fundamentals of Columbia's
					ESP-driven agile SoC methodology, with demonstrated proof points in support of 10-100X improvement in designer productivity; (b)
					domain-specific hardware accelerators for AI/NLP – architecture and design methodology that address customer requirements in real-
					time performance, energy efficiency and security; (c) intelligent task scheduling and compiler support for domain-specific SoCs
					targeted for the important application space of connected autonomous vehicles, easily portable across adjacent application domains.
                    </p>

                </div><!-- /.col-sm-6 -->

                <div class="col-sm-6">

                    <h3 class="section-title multiple-title">Key Topic Areas</h3>

					<p>
                    <ul class="list-arrow-right">
						<li>Artificial Intelligence (AI) and Natural Language Processing (NLP) hardware, with a focus on
						EdgeBERT software-hardware co-designed IP from Harvard.</li>
						<li>Application development for connected autonomous vehicles (ERA) and extended reality
						(ILLIXR) – from IBM and UIUC respectively.</li>
						<li>Energy efficient design with novel distributed hardware power management (DHPM) from IBM
						and Columbia (publication pending).</li>
						<li>Agile, software-hardware co-design methodology driven by ESP from Columbia.</li>
						<li>Efficient programmability via HPVM compiler technology from UIUC.</li>
						<li>Intelligent task scheduling and associated software library from IBM.</li>
						<li>Ontology toolset (e.g. Trireme and Novia) for efficient accelerator discovery from application
						source code – from Harvard, UIUC and IBM.</li>
                    </ul>
					</p>
					
                    <h3 class="section-title multiple-title">Organizing Committee</h3>

                    <p>
					<ul class="list-arrow-right">
						<li>Sarita Adve, University of Illinois at Urbana-Champaign</li>
						<li>Vikram Adve, University of Illinois at Urbana-Champaign</li>
						<li>Pradip Bose, IBM T. J. Watson Research Center</li>
						<li>David Brooks, Harvard University</li>
						<li>Luca Carloni, Columbia University</li>
						<li>Sasa Misailovic, University of Illinois at Urbana-Champaign</li>
						<li>Vijay Janapa Reddi, Harvard University</li>
						<li>Ken Shepard, Columbia University</li>
						<li>Gu-Yeon Wei, Harvard University</li>
					</ul>
                    </p>

                </div><!-- /.col-sm-6 -->
            </div><!-- /.row -->
        </div><!-- /.container -->
    </section>

    <section id="important" class="section bg-image-1 facts text-center">
        <div class="container">
            <div class="row">
                <div class="col-sm-4">
                </div>
                <div class="col-sm-4">

                    <i class="ion-ios-calendar"></i>
                    <h3>Tutorial Date<br>June 29<sup>th</sup>, 2024</h3>
                
                </div>
                <div class="col-sm-4">
                </div>
            </div><!-- row -->
        </div><!-- container -->
    </section>

    <section id="speakers" class="section speakers">
        <div class="container">
			
            <div class="row">
                <div class="col-md-12">
                    <h3 class="section-title">Invited Speakers:</h3>    
                </div>
            </div>

            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/natalia_vassilieva.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>Training Large Language Models on Cerebras Wafer Scale Clusters</h3>
					<h4><a href="https://www.linkedin.com/in/nataliavassilieva" target="_blank">Natalia Vassilieva
						(Sr. Director of Product, Machine Learning - Cerebras Systems)</a></h4>
					<p>
						Large Language Models (LLMs) are shifting “what’s possible”, but require massive compute and massive complexity of distributed training
						across thousands of accelerators with traditional hardware. Cerebras Wafer Scale Clusters make training LLMs faster and easier compared
						to GPUs due to near-perfect linear scaling and simple data-parallel distribution strategy for models of any size. In this talk we will
						share our experience and insights from training various LLMs, including open-sourced family of Cerebras-GPT models, on the Cerebras hardware.
          	  		</p> 
				</div>
            </div>
			
            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/suvinay_subramanian.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>Codesigning Computing Systems for Artificial Intelligence</h3>
					<h4><a href="https://www.linkedin.com/in/suvinay-subramanian-53163b20a/" target="_blank">Suvinay Subramanian
						(Staff Software Engineer - Google)</a></h4>
					<p>
						The rapid advancement of artificial intelligence (AI) has ushered in an era of unprecedented computational demands, necessitating continuous
						innovation in computing systems. In this talk, we will highlight how codesign has been a key paradigm in enabling innovative solutions and
						state-of-the-art performance in Google's AI computing systems, namely Tensor Processing Units (TPUs). We present several codesign case studies
						across different layers of the stack, spanning hardware, systems, software, algorithms, all the way up to the datacenter. We discuss how TPUs
						have made judicious, yet opinionated bets in our design choices, and how these design choices have not only kept pace with the blistering rate
						of change, but also enabled many of the breakthroughs in AI.
          	  		</p> 
				</div>
            </div>
			
            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/carlos_costa.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>Building a Cloud-Native Platform for the Future of AI: Foundation Models</h3>
					<h4><a href="https://www.linkedin.com/in/carlos-h-a-costa-9b9b1a1/" target="_blank">Carlos Costa
						(Principal Research Staff Member - IBM)</a></h4>
					<p>
						Foundation Model is an emerging inflection point in the creation of powerful, very high dimensional data representations, triggered by advances
						in AI. Foundation Models in AI are billion-parameter-scale neural networks, powered by novel architectures which are trained using a technique
						called self-supervision. This new paradigm imposes unprecedented opportunities and challenges across the full computing stack. Hear how IBM Research
						is expanding and realizing the value of Foundation Models, from building a cloud-native supercomputing infrastructure and a simplified, cloud-native
						common stack to train and deploy Foundation Models in an multicloud environment, to applying this full stack to enable advances in natural language
						domain and beyond, including time series and code generation. 
          	  		</p> 
				</div>
            </div>

            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/tushar_krishna.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>Modeling and Mitigating Communication Bottlenecks for Large Model Training at Scale</h3>
					<h4><a href="https://www.linkedin.com/in/tushar-krishna-a60b0970/" target="_blank">Tushar Krishna
						(Associate Professor - Georgia Institute of Technology)</a></h4>
					<p>
						The unprecedented success of large language models (LLMs) &mdash; such as Open AI's GPT-3 and GPT-4, Google's Bard, Meta's LLaMa , Cerebras-GPT and
						others &mdash; is emphasizing the ever-growing demand to efficiently train them. These models leverage billions to trillions of model parameters and
						this trend continues to increase at an unforeseen rate. The large model size makes it impossible for their parameters to fit within a single accelerator
						device, whose memory is usually capped at tens of GBs. Furthermore, even if we succeed to fit the model into a single device, their tremendous compute
						requirement leads to almost impractical training time. For example, GPT-3 consists of 175B parameters and takes 355 GPU-years to train with a single
						NVIDIA V100 GPU. This has led to a growing interest in distributed training, which is the idea of sharding model weights and/or data samples across
						multiple accelerator devices. However, this comes at the expense of communication overhead to exchange gradients and activations, and it has already
						become a key bottleneck for distributed training. We identify that the communication challenge will get exacerbated in future systems that are expected
						to leverage multi-dimensional networks with heterogeneous bandwidths due to diverse fabric technologies (e.g., chiplets, rack-scale, and scaleout).
						We present our recent works on <em>(i)</em> modeling future training platforms to identify such bottlenecks, and <em>(ii)</em> a novel runtime scheduling
						policy to enhance network bandwidth utilization.
          	  		</p> 
				</div>
            </div>
		
<!--
            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/tajana_rosing.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>End-to-End Learning with Fully Homomorphic Encryption in Memory</h3>
					<h4><a href="https://cseweb.ucsd.edu/~trosing/" target="_blank">Tajana Šimunić Rosing
						(University of California, San Diego)</a></h4>
					<p>
						The increasing amount of data and the growing complexity of problems has resulted in an ever-growing reliance on cloud computing.
						However, many applications, most notably in healthcare, finance or defense, demand security and privacy which today's solutions cannot
						fully address. Fully homomorphic encryption (FHE) elevates the bar of today's solutions by adding confidentiality of data during processing.
						It allows computation on fully encrypted data without the need for decryption, thus fully preserving privacy. To enable processing encrypted
						data at usable levels of classic security, e.g., 128-bit, the encryption procedure introduces noticeable data size expansion &mdash; the
						ciphertext is much bigger than the native aggregate of native data types. In this talk, we present MemFHE which is the first accelerator of
						both client and server for the latest Ring-GSW (Gentry, Sahai, and Waters) based homomorphic encryption schemes using Processing In Memory
						(PIM). PIM alleviates the data movement issues with large FHE encrypted data, while providing in-situ execution and extensive parallelism
						needed for FHE’s polynomial operations. While the client-PIM can homomorphically encrypt and decrypt data, the server-PIM can process
						homomorphically encrypted data without decryption. Our server-PIM is pipelined and is designed to provide flexible bootstrapping, allowing
						two encryption techniques and various FHE security-levels based on the application requirements. We evaluate our design at various security-levels
						and compare it with state-of-the-art CPU implementations for Ring-GSW based FHE. Our system is up to 20k&times; (265&times;) faster than CPU (GPU)
						for FHE arithmetic operations and provides on average 2007&times; higher throughput than the state of the art while implementing learning algorithms
						with FHE.
          	  		</p> 
				</div>
            </div>

            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/ro_cammarota.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>Homomorphic Computing, with a Focus on Hardware-Accelerated Homomorphic Encryption</h3>
					<h4><a href="https://www.intel.com/content/www/us/en/research/researchers/ro-cammarota.html" target="_blank">Rosario Cammarota
						(Intel)</a></h4>
					<p>
						Enabling processing encrypted data elevates the bar of confidentiality in existing security solutions and opens the front to new applications.
						It preserves individuals' privacy and market competitiveness while sustaining societal and economic growth through data sharing, collaboration,
						and artificial intelligence. Homomorphic Encryption (HE) is a unique family of cryptographic methods to process encrypted data. HE applications
						can reduce the risk of third-party data leakage at the processing node while preserving both data ownership and lifecycle. However, the performance
						gap that even the most efficient HE schemes hinder enabling meaningful HE applications and adopting the technology. HE applications can be a million
						times slower than the corresponding unencrypted applications on existing hardware architectures. Other barriers to adoption include the lack of
						development tools to reduce non-recurring engineering costs to build HE applications and the lack of international standards.
						Innovation in hardware architecture is the first step in bridging the performance gap and setting directions to enable meaningful technology adoption.
						In this talk, I will share Intel's innovation from theory to algorithms down to hardware architecture to allow the adoption of processing encrypted
						data with HE. Jointly with Microsoft, our Standards & Industry Organization and academic partners, we develop novel HE platforms comprehensive of
						revolutionary hardware, software libraries, development tools, and applications to make HE technologies accessible, performant, and cost-effective.
						We build an ecosystem that can sustain the exponential growth of HE-based technologies.
          	  		</p> 
				</div>
            </div>

            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/hayim_shaul.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>CircLayer &mdash; Circuit Optimization &amp; Scheduling Made Easy</h3>
					<h4><a href="https://www.linkedin.com/in/hayim-shaul-b2658/?originalSubdomain=il" target="_blank">Hayim Shaul
						(IBM Research)</a></h4>
					<p>
						CircLayer is a circuit abstraction layer part of the HELayers end-to-end framework to write high level fully homomorphic encryption code. CircLayer
						lets the researcher apply optimizations directly on the circuit level. In addition it gives control on scheduling decisions made when executing the
						circuit. This makes CircLayer an ideal choice for researches and developers who develop new optimization and scheduling algorithms.
          	  		</p> 
				</div>
            </div>

            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/kevin_barker.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>Codesigning the Next Generation of Intelligent Computing Systems</h3>
					<h4><a href="https://www.pnnl.gov/people/kevin-j-barker" target="_blank">Kevin Barker
						(Pacific Northwest National Laboratory)</a></h4>
					<p>
						Convergence is driving the emergence of tightly integrated scientific workflows that combine physical simulation, machine learning, and analytics.
						However, such workflows are not well-served by existing computing capabilities that separate HPC and AI/ML computing paradigms into distinct ecosystems.
						While co-processor accelerators such as GPUs have been successfully applied to both HPC and AI/ML workloads, software stacks, programming languages, and
						programming models are still largely incompatible. Additionally, many scientific machine learning workloads exhibit characteristics that hamper their 
						performance on GPU throughput-oriented architectures. In this talk, we discuss our vision of the codesign process, as well as ongoing efforts at Pacific
						Northwest National Laboratory in codesigning hardware and software stacks to support this notion of convergence and the next generation of scientific computing.
          	  		</p> 
				</div>
            </div>
-->

		</div>
    </section>

    <section id="program" class="section schedule">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <h3 class="section-title">Program:</h3>
					
                    <p>
                    <table class="table table-hover">
                      <thead class="thead-light">
                        <tr>
                          <th colspan=2 scope="col">Sunday June 18<sup>th</sup>, 2023<br><em>(all times are Eastern Time)</em></th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <th scope="row" class="col-md-3">9:00 - 9:15 AM</th>
                          <td>Introduction and Welcoming Remarks</td>
                        </tr>
                        <tr bgcolor="#EBF5FB">
                          <th scope="row">9:15 - 10:00 AM</th>
                          <td><strong>Invited Talk:</strong> "Building a Cloud-Native Platform for the Future of AI: Foundation Models"<br>
							  Carlos Costa <em>(IBM Research)</em></td>
                        </tr>
                        <tr>
                          <th scope="row">10:00 - 10:15 AM</th>
                          <td>"PDR-CapsNet: an Energy-Efficient Parallel Approach to Dynamic Routing in Capsule Networks"<br>
							  Samaneh Javadinia and Amirali Baniasadi <em>(University of Victoria)</em></td>
                        </tr>
                        <tr>
                          <th scope="row">10:15 - 10:30 AM</th>
                          <td>"Bit Error Characterization in Fault-Prone Homomorphic Encryption Applications"<br>
							  Matias Mazzanti and Esteban Mocskos <em>(University of Buenos Aires)</em></td>
                        </tr>
                        <tr>
                          <th scope="row">10:30 - 10:45 AM</th>
                          <td>"Object Detection and Classification on a Heterogeneous Edge SoC"<br>
							  Gracen Wallace, Aporva Amarnath, Nandhini Chandramoorthy and Augusto Vega <em>(IBM Research)</em></td>
                        </tr>
                        <tr>
                          <th scope="row">10:45 - 11:00 AM</th>
                          <td>"Diagnosis of Sports Injuries: A Hardware-Optimized Deep Learning Solution"<br>
							  Ronak Das</td>
                        </tr>
                        <tr bgcolor="#FEF9E7">
                          <th scope="row">11:00 - 11:30 AM</th>
                          <td><i>Break</i></td>
                        </tr>
                        <tr bgcolor="#EBF5FB">
                          <th scope="row">11:30 - 12:15 PM</th>
                          <td><strong>Invited Talk:</strong> "Codesigning Computing Systems for Artificial Intelligence"<br>
							  Suvinay Subramanian <em>(Google)</em></td>
                        </tr>
                        <tr>
                          <th scope="row">12:15 - 12:30 PM</th>
                          <td>"Qualitative Study of Facial Recognition Algorithm through Hardware-Software Acceleration"<br>
							  Mohammed  Samiulla, Prithvi Naidu, Prajwal Naidu and Advaith Jagannath <em>(New York University)</em></td>
                        </tr>
                        <tr bgcolor="#FEF9E7">
                          <th scope="row">12:30 - 2:00 PM</th>
                          <td><i>Lunch</i></td>
                        </tr>
                        <tr bgcolor="#EBF5FB">
                          <th scope="row">2:00 - 2:45 PM</th>
                          <td><strong>Invited Talk:</strong> "Modeling and Mitigating Communication Bottlenecks for Large Model Training at Scale"<br>
							  Tushar Krishna <em>(Georgia Institute of Technology)</em></td>
                        </tr>
                        <tr bgcolor="#EBF5FB">
                          <th scope="row">2:45 - 3:30 PM</th>
                          <td><strong>Invited Talk:</strong> "Training Large Language Models on Cerebras Wafer Scale Clusters"<br>
							  Natalia Vassilieva <em>(Cerebras Systems)</em></td>
                        </tr>
                        <tr bgcolor="#FEF9E7">
                          <th scope="row">3:30 - 4:00 PM</th>
                          <td><i>Break</i></td>
                        </tr>
                        <tr bgcolor="#EBF5FB">
                          <th scope="row">4:00 - 5:00 PM</th>
                          <td><strong>Panel: "AI Futures: Rosy, Scary or Blah?"</strong><br>
							  This panel will debate the future of AI from the view point of society in general and computer architects/scientists in particular.
							  In many ways, the first indications of scary excitement (beyond normal science fiction giddiness) came in 2011, with Ken Jennings
							  (human Jeopardy champion) uttering those famous words: <a href="https://www.youtube.com/watch?v=wvSBzKbecmo" target="_blank">«I for
							  one welcome our new computer overlords!»</a>. Since then, with the steady and steep rise of AI/ML capabilities, the awe and excitement
							  seems to be turning into downright panic, given the statements being made by some of the modern-day pioneers/catalysts of the AI/ML
							  revolution as well as notable other scientists and intellectuals.<br>
							  After the panelists provide their position statements, the floor will be open for Q&A, with questions posed from the audience.
						  </td>
                        </tr>						
                        <tr>
                          <th scope="row">5:00 PM</th>
                          <td>Concluding Remarks</td>
                        </tr>
                      </tbody>
                    </table>
                    </p>

                </div>
            </div>
        </div>
    </section>
    
    <section id="org" class="section registration">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <h3 class="section-title">Organizers</h3>
                </div>
				
                <div class="col-md-4">
                <p>                    
                <b><a href="https://www.pnnl.gov/people/roberto-gioiosa" rel="nofollow" target="_blank">Roberto Gioiosa</a> </b>is a senior researcher
				in the HPC group and lead of the Scalable and Emerging Technologies team at Pacific Northwest National Laboratory. His current research
				focuses on hardware/software co-design methodologies, custom AI/ML accelerator designs, and distributed software for heterogeneous systems.
				Currently, Dr. Gioiosa leads the DOE co-design center for AI and graph analytics (ARIAA) and leads several other co-design efforts at PNNL.
                In the past, Dr. Gioiosa worked at LANL, BSC, IBM Watson, and ORNL. Dr. Gioiosa holds a Ph.D. from the University of Rome “Tor Vergata”.
                </p>
                <p>
                <b><a href="https://www.linkedin.com/in/davidtrilla/" rel="nofollow" target="_blank">David Trilla</a> </b>is a post-doctoral Researcher at
				IBM T. J. Watson Research Center. He has worked on critical-embedded real-time systems and his current research interests include security
				and agile hardware development. He obtained his Ph.D. at the Barcelona Supercomputing Center (BSC) granted by the Polytechnic University of
				Catalonia (UPC), Spain.
                </p>
                <p>
                <b><a href="https://www.linkedin.com/in/palsubhankar/" rel="nofollow" target="_blank">Subhankar Pal</a> </b>is a Research Staff Member
				at IBM T. J. Watson Research Center. His research is focused on SoC design methodologies and hardware-software co-design for
				privacy-preserving machine learning. He holds a Ph.D. and M.S. from the University of Michigan. His Ph.D. thesis looked at designing a
				reconfigurable, software-defined hardware solution that balances programmability with energy efficiency. Prior to that, Subhankar was
				with NVIDIA, where he worked on pre-silicon verification and bring-up of multiple generations of GPUs.
                </p>
                <p>
                <b><a href="http://researcher.watson.ibm.com/researcher/view.php?person=us-kvswamin" rel="nofollow" 
                target="_blank">Karthik Swaminathan</a> </b>is a Research Staff Member at IBM T. J. Watson Research Center. His research
                interests include power-aware architectures, domain-specific accelerators and emerging device technologies in processor
                design. He is also interested in architectures for approximate and cognitive computing, particularly in aspects related to
                their reliability and energy efficiency. He holds a Ph.D. degree from Penn State University.
                </p>
				</div>
				
                <div class="col-md-4">
                <p>
                <b><a href="https://researcher.draco.res.ibm.com/researcher/view.php?person=us-chcost" rel="nofollow" target="_blank">Carlos Costa</a> </b>
				is a Principal Research Staff Member at IBM T. J. Watson Research Center, where he leads the effort to build a serverless, cloud-native
				platform for emerging AI/ML workflows. His research is mainly focused on system software, programming models and middleware for next-generation
				distributed systems, working at the intersection of traditional HPC and emerging distributed computing paradigms. He has been involved in
				multiple projects in the areas of HPC and analytics, including the BlueGene/Q system, the Active Memory Cube (AMC) architecture for in-memory
				processing, and DoE ORNL’s Summit and LLNL’s Sierra supercomputer systems, among other projects with clients and academic partners. He is
				currently the lead of IBM Research’s Foundation Model Stack.
                </p>
                <p>
                <b><a href="http://researcher.watson.ibm.com/researcher/view.php?person=us-alperb" rel="nofollow" target="_blank">Alper 
                Buyuktosunoglu</a> </b>is a Research Staff Member at IBM T. J. Watson Research Center. He has been involved in research and
                development work in support of IBM Power Systems and IBM z Systems in the area of high performance, reliability and power-aware 
                computer architectures. He holds a Ph.D. degree from University of Rochester.
                </p>
                <p>
                <b><a href="http://researcher.watson.ibm.com/researcher/view.php?person=us-pbose" rel="nofollow" target="_blank">Pradip 
                Bose</a> </b>is a Distinguished Research Staff Member and manager of <i>Efficient and Resilient Systems</i> at IBM T. J. 
                Watson Research Center. He has over thirty-three years of experience at IBM, and was a member of the pioneering RISC super 
                scalar project at IBM (a pre-cursor to the first RS/6000 system product). He holds a Ph.D. degree from University of Illinois 
                at Urbana-Champaign.
                </p>
                <p>
                <b><a href="https://www.linkedin.com/in/augusto-vega-5940684" rel="nofollow" target="_blank">Augusto Vega</a> </b>is a 
                Research Staff Member at IBM T. J. Watson Research Center involved in research and development work in the areas of 
                highly-reliable power-efficient embedded designs, cognitive systems and mobile computing. He holds a Ph.D. degree from 
                Polytechnic University of Catalonia (UPC), Spain.
                </p>
                <p>
                <b><a href="https://anands09.github.io" rel="nofollow" target="_blank">Ananda Samajdar</a> </b>is a Research Staff Member
				at IBM T. J. Watson Research Center working on accelerator design and compilation/mapping strategies for DNN workloads on
				IBM’s RaPiD AI accelerator. He holds a Ph.D. from Georgia Tech.
                </p>
                </div>
                <div id="contact" class="col-md-4">
                    <h4 class="section-title">Contact</h4>
                    <ul class="list-arrow-right">
                    <li><a href="mailto:info@epochs-project.com">info@epochs-project.com</a></li> 
                    </ul>
                </div>
            </div>
        </div>
    </section>

<!--
    <section id="facts" class="section bg-image-1 facts text-center">
        <div class="container">
            <div class="row">
                <div class="col-sm-6">

                    <i class="ion-earth"></i>
                    <h3><a href="http://researcher.watson.ibm.com/researcher/view_group_subpage.php?id=6586" rel="nofollow" target="_blank">CogArch 2015</a></h3>
                
                </div>
                <div class="col-sm-6">

                    <i class="ion-earth"></i>
                    <h3><a href="http://researcher.watson.ibm.com/researcher/view_group.php?id=5848" rel="nofollow" target="_blank">CogArch 2016</h3>
                
                </div>
            </div>
        </div>
    </section>
-->

    <section id="links" class="section bg-image-2 facts ">
        <div class="container">
            <div class="row">
				<div class="col-md-12">
                    <h3 class="section-title">Interesting Links</h3>
                </div>
				<div class="col-md-3">
                    <p>The <a href="http://www.computerhistory.org/timeline/ai-robotics/" target="_blank">AI and Robotics Timeline</a> from 1939 to date</p>
                </div>
				<div class="col-md-3">
                    <p>The <a href="http://research.ibm.com/cognitive-computing/" target="_blank">AI portal</a> with the latest research activities conducted by IBM on AI</p>
                </div>
				<div class="col-md-3">
                    <p>The <a href="https://research.ibm.com/topics/foundation-models" target="_blank">Foundation Models</a> portal</p>
                </div>
				<div class="col-md-3">
                    <p>IBM Watson in action in this <a href="https://www.ibm.com/demos/live/tts-demo/self-service/home" target="_blank">text-to-speech demo</a></p>
                </div>
          </div>
        </div>
    </section>


    <section id="location" class="section location">
        <div class="container">
            <div class="row">
			
				<div id="registration" class="col-md-3">
                    <h3 class="section-title">Registration</h3>

                    <p>
                    The tutorial will be held in conjunction with the <b><a href="https://iscaconf.org/isca2024/" target="_blank">
					51<sup>st</sup> International Symposium on Computer Architecture (ISCA 2024)</a></b>.
                    Refer to the main venue to continue with the registration process.
                    </p>
                </div>


                <div class="col-sm-3">
                    <h3 class="section-title">Event Location</h3>
                    <address>
					  <p>Hilton Buenos Aires<br>
					  Macacha Güemes 351<br>
					  Buenos Aires, Argentina
                      </p>
                    </address>
                    
                    <p><b><a href="https://iscaconf.org/isca2024/" target="_blank"> Check main venue site for more information.</a></b></p>

                </div>
                <div class="col-sm-6">
				  <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d105073.4534029788!2d-58.51569893714634!3d-34.61565476952265!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x95bcca3b4ef90cbd%3A0xa0b3812e88e88e87!2sBuenos%20Aires%2C%20Argentina!5e0!3m2!1sen!2sus!4v1710540815941!5m2!1sen!2sus" width="600" height="450" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>
                </div>
            </div>
        </div>
    </section>


    <footer class="site-footer facts">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <p class="site-info">Share this event on your social networks</p>
                </div>
                <div class="col-md-4">
                    <a href="https://twitter.com/home?status=Check%20out%20the%20Workshop%20on%20Cognitive%20Architectures%0Ahttps%3A//cogarchworkshop.org"><i class="ion-social-twitter"></i>&nbsp; Twitter</a>
                </div>
                <div class="col-md-4">
                    <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//cogarchworkshop.org/"><i class="ion-social-facebook"></i>&nbsp; Facebook</a>
                </div>
                <div class="col-md-4">
                    <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A//cogarchworkshop.org/&title=Workshop%20on%20Cognitive%20Architectures&summary=&source="><i class="ion-social-linkedin-outline"></i>&nbsp; LinkedIn</a>
                </div>
            </div>
        </div>
    </footer>

    <!-- script -->
    <script src="bower_components/jquery/dist/jquery.min.js"></script>
    <script src="bower_components/bootstrap/dist/js/bootstrap.min.js"></script>
    <script src="bower_components/smooth-scroll/dist/js/smooth-scroll.min.js"></script>
    <script src="assets/js/main.js"></script>
</body>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-88908704-1', 'auto');
  ga('send', 'pageview');

</script>
  
</html>
