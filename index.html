<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Workshop on Cognitive Architectures</title>

    <!-- css -->
    <link rel="stylesheet" href="bower_components/bootstrap/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="bower_components/ionicons/css/ionicons.min.css">
    <link rel="stylesheet" href="assets/css/main.css">
</head>
<body data-spy="scroll" data-target="#site-nav">
    <nav id="site-nav" class="navbar navbar-fixed-top navbar-custom">
        <div class="container">
            <div class="navbar-header">

                <!-- logo -->
                <div class="site-branding">
                    <a class="logo" href="index.html">
                        
                        <!-- logo image  -->
                        <!-- <img src="assets/images/logo.png" alt="Logo"> -->
                        CogArch
                    </a>
                </div>

                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-items" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>

            </div><!-- /.navbar-header -->

            <div class="collapse navbar-collapse" id="navbar-items">
                <ul class="nav navbar-nav navbar-right">

                    <!-- navigation menu -->
                    <li class="active"><a data-scroll href="#about">About</a></li>
                    <li><a data-scroll href="#about">Call for Contributions</a></li>
                    <li><a data-scroll href="#speakers">Speakers</a></li>         
                    <li><a data-scroll href="#program">Program</a></li>
                    <li><a data-scroll href="#prev">Past Editions</a></li>
                    <li><a data-scroll href="#org">Organizers</a></li>
                
                </ul>
            </div>
        </div><!-- /.container -->
    </nav>

    <header id="site-header" class="site-header valign-center"> 
        <div class="intro">

            <p>June 18<sup>th</sup> 2023, Orlando, FL, USA</p>

            <h1>CogArch 2023</h1>            
            <h1>7<sup>th</sup> Workshop on Cognitive Architectures</h1>
			
			<h2 style="color: #FF7A59"><em><strong>Foundation Models and the Architectural Implications of Scalable AI</strong></em></h2>
            
            <p>In conjunction with the 50<sup>th</sup> International Symposium<br>
                on Computer Architecture (ISCA 2023)</p>
            
            <a class="btn btn-white" data-scroll href="#about">Contribute Now</a>

            <a class="btn btn-white" data-scroll href="#registration">Register Now</a>
        
        </div>
    </header>

    <section id="about" class="section about">
        <div class="container">
            <div class="row">
                <div class="col-sm-6">

                    <h3 class="section-title">About</h3>
                    
                    <p>
					Artificial Intelligence (AI) and Machine Learning (ML) techniques have become the <em>de facto</em> solution to drive human
					progress and more specifically, automation. In the last years, the world’s economy has been gravitating towards the AI/ML
					domain (from industrial and scientific perspectives) and the expectation of growth is not withering away. In more recent years,
					a new trend towards very large AI models has been gaining traction: <em>Foundation Models</em>. Large Foundation Models with
					billions or trillions of parameters exhibit astonishing emergent skills, especially in fields like natural language processing,
					vision, and human-machine interaction. Examples like BERT (110M parameters), GPT-2 (1.5B parameters), GPT-3 (175B parameters), BLOOM
					(176B parameters), and Wu Dao (1.75T parameters!) indicate that the size of these models will keep growing rapidly and substantially
					in the foreseeable future. This results in all sorts of challenges, especially with respect to provisioning the computing resources
					needed for training and inferencing, and calls for thorough co-design across algorithms, models, software, and hardware systems.
				    </p>
					<p>
					In this context, this edition of the <strong>CogArch workshop</strong> aims at bringing together the necessary know-how to address
					co-designed hardware-software architectures from a holistic point of view, tackling all their design considerations from the algorithms
					to platforms in all the different fields that large-scale cognitive systems will soon occupy, from natural language processing and speech
					to other applications like protein folding, drug discovery, computer vision or even music generation.
				    </p>
					<p> 
					The <strong>CogArch workshop</strong> already had six successful editions, bringing together experts and knowledge on the most novel
					design ideas for cognitive systems. This workshop capitalizes on the synergy between industrial and academic efforts in order to provide
					a better understanding of cognitive systems and key concepts of their design.
                    </p>

                    <h3 class="section-title multiple-title">Call for Papers</h3>

                    <p>
					Hardware and software design considerations are gravitating towards AI applications, as those have been proven extremely useful in a wide
					variety of fields, from edge computing in autonomous cars, to cloud-based computing for personalized medicine. Recent years have witnessed
					the emergence of AI at a very large scale: <em>Foundation Models</em>. Large Foundation Models with billions or trillions of parameters exhibit
					astonishing emergent skills, especially in fields like natural language processing, vision, content creation, and human-machine interaction.
					The unprecedented number of parameters in these models, though, generates all sorts of new challenges, especially with respect to provisioning
					the computing resources needed for training and inferencing, and calls for thorough co-design across algorithms, models, software, and hardware
					systems.
				    </p>
					<p>
					The <strong>CogArch workshop</strong> solicits formative ideas and new product offerings in the general space of AI systems that covers all the
					design aspects of cognitive systems, <strong>with particular focus this year on large-scale Foundation Models</strong>.
					</p>

					<strong>Topics of interest include (but are not limited to):</strong>
                    <ul class="list-arrow-right">
                        <li>Hardware support for state-of-the-art AI models</li>
                        <li>Hardware-software co-design and acceleration of AI models</li>
						<li>Parallelization strategies for AI models (e.g. transformers)</li>
                        <li>Accelerators and micro-architectural support for AI</li>
						<li>Reliability and safety considerations, and security against adversarial attacks in cognitive architectures</li>
                        <li>Techniques for improving energy efficiency of AI applications, and battery life extension and endurance in mobile AI architectures</li>
						<li>AI/ML for fast system modeling and AI/ML as design methodology</li>
						<li>Leveraging 2.5D/3D chiplet designs, wafer scaling and other heterogeneous integration techniques for designing scalable architectures for
							Foundation Models</li>
						<li>Privacy-preserving inference on AI models</li>
						<li>Prototype demonstrations in specific application domains: e.g., natural language processing and speech, protein folding, drug discovery,
							computer vision, code generation, music making, as well as applications of interest to defense and homeland security</li>
                    </ul>

                </div><!-- /.col-sm-6 -->

                <div class="col-sm-6">

					<p>
                    The workshop shall consist of regular presentations and/or prototype demonstrations by authors of selected submissions.
                    In addition, it will include invited keynotes by eminent researchers from industry and academia as well as interactive
                    panel discussions to kindle further interest in these research topics. Submissions will be reviewed by a workshop Program 
                    Committee, in addition to the organizers.
                    </p>
                    
                    <p>
                    Submitted manuscripts must be in English of <strong>up to 2 pages</strong> (with same
                    <a href="https://www.iscaconf.org/isca2023/submit/guidelines.php" target="_blank">formatting guidelines as main 
                    conference</a>) indicating the type of submission: <strong>regular presentation</strong> or <strong>prototype 
                    demonstration</strong>. Submissions should be submitted to the following
					<strong><a href="https://easychair.org/conferences/?conf=cogarch2023" target="_blank">link</a></strong> by
					<del>April 7<sup>th</sup></del> <strong><font color="red">April 21<sup>st</sup>, 2023</font></strong>.
                    <br>
                    If you have questions regarding submission, please contact us:
                    <a href="mailto:info@cogarchworkshop.org">info@cogarchworkshop.org</a>
                    </p>

                    <h3 class="section-title multiple-title">Call for Prototype Demonstrations</h3>

                    <p>
                    CogArch will feature a session where researchers can showcase innovative prototype demonstrations or 
                    <i>proof-of-concept</i> designs in the cognitive architecture space. Examples of such demonstrations may include (but are 
                    not limited to):
                    
                    <ul class="list-arrow-right">
                        <li>Custom ASIC or FPGA-based demonstrations of machine learning, cognitive or neuromorphic architectures.</li>
                        <li>Innovative implementations of state-of-the-art cognitive algorithms/applications, and the underlying 
                            software-hardware co-design techniques.</li>
                        <li>Demonstration of end-to-end cognitive systems comprising of edge devices backed by a cloud computing 
                            infrastructure.</li>
                        <li>Novel designs showcasing the adoption of emerging technologies for the design of cognitive systems.</li>
                        <li>Tools or frameworks to aid analysis, simulation and design of cognitive systems.</li>
                    </ul>

                    Submissions for the demonstration session may be made in the form of a 2-page manuscript highlighting key features and 
                    innovations of the prototype demonstration. Proposals accepted for demonstration during the workshop can be accompanied 
                    by a poster/short presentation. Authors should explicitly indicate that the submission is for <strong>prototype 
                    demonstration</strong> at submission time.
                    </p>

                    <h3 class="section-title multiple-title">Important Dates</h3>
                      
                    <p>
					<ul class="list-arrow-right">
						<li>Paper submission deadline: <del>April 7<sup>th</sup></del> <strong><font color="red">April 21<sup>st</sup>, 2023</font></strong></li>
						<li>Notification of acceptance: May 8<sup>th</sup>, 2023</li>
						<li>Workshop date: June 18<sup>th</sup>, 2023</li>
					</ul>
                    </p>

                    <h3 class="section-title multiple-title">Program Committee</h3>

                    <p>
					<ul class="list-arrow-right">
                        <li>Roberto Gioiosa, Pacific Northwest National Laboratory</li>
                        <li>David Trilla, IBM Research</li>
						<li>Subhankar Pal, IBM Research</li>
                        <li>Karthik Swaminathan, IBM Research</li>
                        <li>Carlos Costa, IBM Research</li>
                        <li>Alper Buyuktosunoglu, IBM Research</li>
                        <li>Pradip Bose, IBM Research</li>
                        <li>Augusto Vega, IBM Research</li>
						<li>Ananda Samajdar, IBM Research</li>
					</ul>
                    </p>
					
					<h3 class="section-title multiple-title">YouTube Channel</h3>
					
					<p>
					<iframe width="392" height="220" src="https://www.youtube.com/embed/videoseries?list=PLTo_S756axY7US3wNyqvHvucGi2XchnwQ"
					title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope;
					picture-in-picture; web-share" allowfullscreen></iframe>
					</p>

                </div><!-- /.col-sm-6 -->
            </div><!-- /.row -->
        </div><!-- /.container -->
    </section>

    <section id="important" class="section bg-image-1 facts text-center">
        <div class="container">
            <div class="row">
                <div class="col-sm-4">

                    <i class="ion-ios-calendar"></i>
                    <h3>Paper Submission Deadline<br>April 21<sup>st</sup>, 2023</h3>
                
                </div>
                <div class="col-sm-4">

                    <i class="ion-ios-calendar"></i>
                    <h3>Notification Date<br>May 8<sup>th</sup>, 2023</h3>
                
                </div>
                <div class="col-sm-4">

                    <i class="ion-ios-calendar"></i>
                    <h3>Workshop Date<br>June 18<sup>th</sup>, 2023</h3>
                
                </div>
            </div><!-- row -->
        </div><!-- container -->
    </section>

    <section id="speakers" class="section speakers">
        <div class="container">
			
            <div class="row">
                <div class="col-md-12">
                    <h3 class="section-title">Invited Speakers:</h3>    
                </div>
            </div>

            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/natalia_vassilieva.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>Training Large Language Models on Cerebras Wafer Scale Clusters</h3>
					<h4><a href="https://www.linkedin.com/in/nataliavassilieva" target="_blank">Natalia Vassilieva
						(Sr. Director of Product, Machine Learning - Cerebras Systems)</a></h4>
					<p>
						Large Language Models (LLMs) are shifting “what’s possible”, but require massive compute and massive complexity of distributed training
						across thousands of accelerators with traditional hardware. Cerebras Wafer Scale Clusters make training LLMs faster and easier compared
						to GPUs due to near-perfect linear scaling and simple data-parallel distribution strategy for models of any size. In this talk we will
						share our experience and insights from training various LLMs, including open-sourced family of Cerebras-GPT models, on the Cerebras hardware.
          	  		</p> 
				</div>
            </div>
			
            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/suvinay_subramanian.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>Codesigning Computing Systems for Artificial Intelligence</h3>
					<h4><a href="https://www.linkedin.com/in/suvinay-subramanian-53163b20a/" target="_blank">Suvinay Subramanian
						(Staff Software Engineer - Google)</a></h4>
					<p>
						The rapid advancement of artificial intelligence (AI) has ushered in an era of unprecedented computational demands, necessitating continuous
						innovation in computing systems. In this talk, we will highlight how codesign has been a key paradigm in enabling innovative solutions and
						state-of-the-art performance in Google's AI computing systems, namely Tensor Processing Units (TPUs). We present several codesign case studies
						across different layers of the stack, spanning hardware, systems, software, algorithms, all the way up to the datacenter. We discuss how TPUs
						have made judicious, yet opinionated bets in our design choices, and how these design choices have not only kept pace with the blistering rate
						of change, but also enabled many of the breakthroughs in AI.
          	  		</p> 
				</div>
            </div>
			
            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/carlos_costa.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>Building a Cloud-Native Platform for the Future of AI: Foundation Models</h3>
					<h4><a href="https://www.linkedin.com/in/carlos-h-a-costa-9b9b1a1/" target="_blank">Carlos Costa
						(Principal Research Staff Member - IBM)</a></h4>
					<p>
						Foundation Model is an emerging inflection point in the creation of powerful, very high dimensional data representations, triggered by advances
						in AI. Foundation Models in AI are billion-parameter-scale neural networks, powered by novel architectures which are trained using a technique
						called self-supervision. This new paradigm imposes unprecedented opportunities and challenges across the full computing stack. Hear how IBM Research
						is expanding and realizing the value of Foundation Models, from building a cloud-native supercomputing infrastructure and a simplified, cloud-native
						common stack to train and deploy Foundation Models in an multicloud environment, to applying this full stack to enable advances in natural language
						domain and beyond, including time series and code generation. 
          	  		</p> 
				</div>
            </div>

            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/tushar_krishna.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>Modeling and Mitigating Communication Bottlenecks for Large Model Training at Scale</h3>
					<h4><a href="https://www.linkedin.com/in/tushar-krishna-a60b0970/" target="_blank">Tushar Krishna
						(Associate Professor - Georgia Institute of Technology)</a></h4>
					<p>
						The unprecedented success of large language models (LLMs) &mdash; such as Open AI's GPT-3 and GPT-4, Google's Bard, Meta's LLaMa , Cerebras-GPT and
						others &mdash; is emphasizing the ever-growing demand to efficiently train them. These models leverage billions to trillions of model parameters and
						this trend continues to increase at an unforeseen rate. The large model size makes it impossible for their parameters to fit within a single accelerator
						device, whose memory is usually capped at tens of GBs. Furthermore, even if we succeed to fit the model into a single device, their tremendous compute
						requirement leads to almost impractical training time. For example, GPT-3 consists of 175B parameters and takes 355 GPU-years to train with a single
						NVIDIA V100 GPU. This has led to a growing interest in distributed training, which is the idea of sharding model weights and/or data samples across
						multiple accelerator devices. However, this comes at the expense of communication overhead to exchange gradients and activations, and it has already
						become a key bottleneck for distributed training. We identify that the communication challenge will get exacerbated in future systems that are expected
						to leverage multi-dimensional networks with heterogeneous bandwidths due to diverse fabric technologies (e.g., chiplets, rack-scale, and scaleout).
						We present our recent works on <em>(i)</em> modeling future training platforms to identify such bottlenecks, and <em>(ii)</em> a novel runtime scheduling
						policy to enhance network bandwidth utilization.
          	  		</p> 
				</div>
            </div>
		
<!--
            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/tajana_rosing.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>End-to-End Learning with Fully Homomorphic Encryption in Memory</h3>
					<h4><a href="https://cseweb.ucsd.edu/~trosing/" target="_blank">Tajana Šimunić Rosing
						(University of California, San Diego)</a></h4>
					<p>
						The increasing amount of data and the growing complexity of problems has resulted in an ever-growing reliance on cloud computing.
						However, many applications, most notably in healthcare, finance or defense, demand security and privacy which today's solutions cannot
						fully address. Fully homomorphic encryption (FHE) elevates the bar of today's solutions by adding confidentiality of data during processing.
						It allows computation on fully encrypted data without the need for decryption, thus fully preserving privacy. To enable processing encrypted
						data at usable levels of classic security, e.g., 128-bit, the encryption procedure introduces noticeable data size expansion &mdash; the
						ciphertext is much bigger than the native aggregate of native data types. In this talk, we present MemFHE which is the first accelerator of
						both client and server for the latest Ring-GSW (Gentry, Sahai, and Waters) based homomorphic encryption schemes using Processing In Memory
						(PIM). PIM alleviates the data movement issues with large FHE encrypted data, while providing in-situ execution and extensive parallelism
						needed for FHE’s polynomial operations. While the client-PIM can homomorphically encrypt and decrypt data, the server-PIM can process
						homomorphically encrypted data without decryption. Our server-PIM is pipelined and is designed to provide flexible bootstrapping, allowing
						two encryption techniques and various FHE security-levels based on the application requirements. We evaluate our design at various security-levels
						and compare it with state-of-the-art CPU implementations for Ring-GSW based FHE. Our system is up to 20k&times; (265&times;) faster than CPU (GPU)
						for FHE arithmetic operations and provides on average 2007&times; higher throughput than the state of the art while implementing learning algorithms
						with FHE.
          	  		</p> 
				</div>
            </div>

            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/ro_cammarota.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>Homomorphic Computing, with a Focus on Hardware-Accelerated Homomorphic Encryption</h3>
					<h4><a href="https://www.intel.com/content/www/us/en/research/researchers/ro-cammarota.html" target="_blank">Rosario Cammarota
						(Intel)</a></h4>
					<p>
						Enabling processing encrypted data elevates the bar of confidentiality in existing security solutions and opens the front to new applications.
						It preserves individuals' privacy and market competitiveness while sustaining societal and economic growth through data sharing, collaboration,
						and artificial intelligence. Homomorphic Encryption (HE) is a unique family of cryptographic methods to process encrypted data. HE applications
						can reduce the risk of third-party data leakage at the processing node while preserving both data ownership and lifecycle. However, the performance
						gap that even the most efficient HE schemes hinder enabling meaningful HE applications and adopting the technology. HE applications can be a million
						times slower than the corresponding unencrypted applications on existing hardware architectures. Other barriers to adoption include the lack of
						development tools to reduce non-recurring engineering costs to build HE applications and the lack of international standards.
						Innovation in hardware architecture is the first step in bridging the performance gap and setting directions to enable meaningful technology adoption.
						In this talk, I will share Intel's innovation from theory to algorithms down to hardware architecture to allow the adoption of processing encrypted
						data with HE. Jointly with Microsoft, our Standards & Industry Organization and academic partners, we develop novel HE platforms comprehensive of
						revolutionary hardware, software libraries, development tools, and applications to make HE technologies accessible, performant, and cost-effective.
						We build an ecosystem that can sustain the exponential growth of HE-based technologies.
          	  		</p> 
				</div>
            </div>

            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/hayim_shaul.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>CircLayer &mdash; Circuit Optimization &amp; Scheduling Made Easy</h3>
					<h4><a href="https://www.linkedin.com/in/hayim-shaul-b2658/?originalSubdomain=il" target="_blank">Hayim Shaul
						(IBM Research)</a></h4>
					<p>
						CircLayer is a circuit abstraction layer part of the HELayers end-to-end framework to write high level fully homomorphic encryption code. CircLayer
						lets the researcher apply optimizations directly on the circuit level. In addition it gives control on scheduling decisions made when executing the
						circuit. This makes CircLayer an ideal choice for researches and developers who develop new optimization and scheduling algorithms.
          	  		</p> 
				</div>
            </div>

            <div class="row">
                <div class="col-md-2">
                    <div class="speaker">
                        <figure>
                            <img alt="" class="img-responsive center-block" src="assets/images/speakers/kevin_barker.jpg" style="border-radius:50%">
                        </figure>
                    </div>
                </div>

                <div class="col-sm-10">
					<h3>Codesigning the Next Generation of Intelligent Computing Systems</h3>
					<h4><a href="https://www.pnnl.gov/people/kevin-j-barker" target="_blank">Kevin Barker
						(Pacific Northwest National Laboratory)</a></h4>
					<p>
						Convergence is driving the emergence of tightly integrated scientific workflows that combine physical simulation, machine learning, and analytics.
						However, such workflows are not well-served by existing computing capabilities that separate HPC and AI/ML computing paradigms into distinct ecosystems.
						While co-processor accelerators such as GPUs have been successfully applied to both HPC and AI/ML workloads, software stacks, programming languages, and
						programming models are still largely incompatible. Additionally, many scientific machine learning workloads exhibit characteristics that hamper their 
						performance on GPU throughput-oriented architectures. In this talk, we discuss our vision of the codesign process, as well as ongoing efforts at Pacific
						Northwest National Laboratory in codesigning hardware and software stacks to support this notion of convergence and the next generation of scientific computing.
          	  		</p> 
				</div>
            </div>
-->

		</div>
    </section>

    <section id="program" class="section schedule">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <h3 class="section-title">Program:</h3>
					
                    <p>
                    <table class="table table-hover">
                      <thead class="thead-light">
                        <tr>
                          <th colspan=2 scope="col">Sunday June 18<sup>th</sup>, 2023<br><em>(all times are Eastern Time)</em></th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <th scope="row" class="col-md-3">9:00 - 9:15 AM</th>
                          <td>Introduction and Welcoming Remarks</td>
                        </tr>
                        <tr bgcolor="#EBF5FB">
                          <th scope="row">9:15 - 10:00 AM</th>
                          <td><strong>Invited Talk:</strong> "Building a Cloud-Native Platform for the Future of AI: Foundation Models"<br>
							  Carlos Costa <em>(IBM Research)</em></td>
                        </tr>
                        <tr>
                          <th scope="row">10:00 - 10:15 AM</th>
                          <td>"PDR-CapsNet: an Energy-Efficient Parallel Approach to Dynamic Routing in Capsule Networks"<br>
							  Samaneh Javadinia and Amirali Baniasadi <em>(University of Victoria)</em></td>
                        </tr>
                        <tr>
                          <th scope="row">10:15 - 10:30 AM</th>
                          <td>"Bit Error Characterization in Fault-Prone Homomorphic Encryption Applications"<br>
							  Matias Mazzanti and Esteban Mocskos <em>(University of Buenos Aires)</em></td>
                        </tr>
                        <tr>
                          <th scope="row">10:30 - 10:45 AM</th>
                          <td>"Object Detection and Classification on a Heterogeneous Edge SoC"<br>
							  Gracen Wallace, Aporva Amarnath, Nandhini Chandramoorthy and Augusto Vega <em>(IBM Research)</em></td>
                        </tr>
                        <tr>
                          <th scope="row">10:45 - 11:00 AM</th>
                          <td>"Diagnosis of Sports Injuries: A Hardware-Optimized Deep Learning Solution"<br>
							  Ronak Das</td>
                        </tr>
                        <tr bgcolor="#FEF9E7">
                          <th scope="row">11:00 - 11:30 AM</th>
                          <td><i>Break</i></td>
                        </tr>
                        <tr bgcolor="#EBF5FB">
                          <th scope="row">11:30 - 12:15 PM</th>
                          <td><strong>Invited Talk:</strong> "Codesigning Computing Systems for Artificial Intelligence"<br>
							  Suvinay Subramanian <em>(Google)</em></td>
                        </tr>
                        <tr>
                          <th scope="row">12:15 - 12:30 PM</th>
                          <td>"Qualitative Study of Facial Recognition Algorithm through Hardware-Software Acceleration"<br>
							  Mohammed  Samiulla, Prithvi Naidu, Prajwal Naidu and Advaith Jagannath <em>(New York University)</em></td>
                        </tr>
                        <tr bgcolor="#FEF9E7">
                          <th scope="row">12:30 - 2:00 PM</th>
                          <td><i>Lunch</i></td>
                        </tr>
                        <tr bgcolor="#EBF5FB">
                          <th scope="row">2:00 - 2:45 PM</th>
                          <td><strong>Invited Talk:</strong> "Modeling and Mitigating Communication Bottlenecks for Large Model Training at Scale"<br>
							  Tushar Krishna <em>(Georgia Institute of Technology)</em></td>
                        </tr>
                        <tr bgcolor="#EBF5FB">
                          <th scope="row">2:45 - 3:30 PM</th>
                          <td><strong>Invited Talk:</strong> "Training Large Language Models on Cerebras Wafer Scale Clusters"<br>
							  Natalia Vassilieva <em>(Cerebras Systems)</em></td>
                        </tr>
                        <tr bgcolor="#FEF9E7">
                          <th scope="row">3:30 - 4:00 PM</th>
                          <td><i>Break</i></td>
                        </tr>
                        <tr bgcolor="#EBF5FB">
                          <th scope="row">4:00 - 5:00 PM</th>
                          <td><strong>Panel: "AI Futures: Rosy, Scary or Blah?"</strong><br>
							  This panel will debate the future of AI from the view point of society in general and computer architects/scientists in particular.
							  In many ways, the first indications of scary excitement (beyond normal science fiction giddiness) came in 2011, with Ken Jennings
							  (human Jeopardy champion) uttering those famous words: <a href="https://www.youtube.com/watch?v=wvSBzKbecmo" target="_blank">«I for
							  one welcome our new computer overlords!»</a>. Since then, with the steady and steep rise of AI/ML capabilities, the awe and excitement
							  seems to be turning into downright panic, given the statements being made by some of the modern-day pioneers/catalysts of the AI/ML
							  revolution as well as notable other scientists and intellectuals.<br>
							  After the panelists provide their position statements, the floor will be open for Q&A, with questions posed from the audience.
						  </td>
                        </tr>						
                        <tr>
                          <th scope="row">5:00 PM</th>
                          <td>Concluding Remarks</td>
                        </tr>
                      </tbody>
                    </table>
                    </p>

                </div>
            </div>
        </div>
    </section>
    
    <section id="prev" class="section schedule">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <h3 class="section-title">Past Editions:</h3>
					<ul class="list-arrow-right">
                    <li><a href="https://augustojv.github.io/cogarch-workshop-2022/">2022</a></li>
                    <li><a href="https://augustojv.github.io/cogarch-workshop-2021/">2021</a></li>
                    <li><a href="https://augustojv.github.io/cogarch-workshop-2020/">2020</a></li>
					<li><a href="https://augustojv.github.io/cogarch-workshop-2018/">2018</a></li>
					</ul>
                </div>
            </div>
        </div>
    </section>


    <section id="org" class="section registration">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <h3 class="section-title">Organizers</h3>
                </div>
				
                <div class="col-md-4">
                <p>                    
                <b><a href="https://www.pnnl.gov/people/roberto-gioiosa" rel="nofollow" target="_blank">Roberto Gioiosa</a> </b>is a senior researcher
				in the HPC group and lead of the Scalable and Emerging Technologies team at Pacific Northwest National Laboratory. His current research
				focuses on hardware/software co-design methodologies, custom AI/ML accelerator designs, and distributed software for heterogeneous systems.
				Currently, Dr. Gioiosa leads the DOE co-design center for AI and graph analytics (ARIAA) and leads several other co-design efforts at PNNL.
                In the past, Dr. Gioiosa worked at LANL, BSC, IBM Watson, and ORNL. Dr. Gioiosa holds a Ph.D. from the University of Rome “Tor Vergata”.
                </p>
                <p>
                <b><a href="https://www.linkedin.com/in/davidtrilla/" rel="nofollow" target="_blank">David Trilla</a> </b>is a post-doctoral Researcher at
				IBM T. J. Watson Research Center. He has worked on critical-embedded real-time systems and his current research interests include security
				and agile hardware development. He obtained his Ph.D. at the Barcelona Supercomputing Center (BSC) granted by the Polytechnic University of
				Catalonia (UPC), Spain.
                </p>
                <p>
                <b><a href="https://www.linkedin.com/in/palsubhankar/" rel="nofollow" target="_blank">Subhankar Pal</a> </b>is a Research Staff Member
				at IBM T. J. Watson Research Center. His research is focused on SoC design methodologies and hardware-software co-design for
				privacy-preserving machine learning. He holds a Ph.D. and M.S. from the University of Michigan. His Ph.D. thesis looked at designing a
				reconfigurable, software-defined hardware solution that balances programmability with energy efficiency. Prior to that, Subhankar was
				with NVIDIA, where he worked on pre-silicon verification and bring-up of multiple generations of GPUs.
                </p>
                <p>
                <b><a href="http://researcher.watson.ibm.com/researcher/view.php?person=us-kvswamin" rel="nofollow" 
                target="_blank">Karthik Swaminathan</a> </b>is a Research Staff Member at IBM T. J. Watson Research Center. His research
                interests include power-aware architectures, domain-specific accelerators and emerging device technologies in processor
                design. He is also interested in architectures for approximate and cognitive computing, particularly in aspects related to
                their reliability and energy efficiency. He holds a Ph.D. degree from Penn State University.
                </p>
				</div>
				
                <div class="col-md-4">
                <p>
                <b><a href="https://researcher.draco.res.ibm.com/researcher/view.php?person=us-chcost" rel="nofollow" target="_blank">Carlos Costa</a> </b>
				is a Principal Research Staff Member at IBM T. J. Watson Research Center, where he leads the effort to build a serverless, cloud-native
				platform for emerging AI/ML workflows. His research is mainly focused on system software, programming models and middleware for next-generation
				distributed systems, working at the intersection of traditional HPC and emerging distributed computing paradigms. He has been involved in
				multiple projects in the areas of HPC and analytics, including the BlueGene/Q system, the Active Memory Cube (AMC) architecture for in-memory
				processing, and DoE ORNL’s Summit and LLNL’s Sierra supercomputer systems, among other projects with clients and academic partners. He is
				currently the lead of IBM Research’s Foundation Model Stack.
                </p>
                <p>
                <b><a href="http://researcher.watson.ibm.com/researcher/view.php?person=us-alperb" rel="nofollow" target="_blank">Alper 
                Buyuktosunoglu</a> </b>is a Research Staff Member at IBM T. J. Watson Research Center. He has been involved in research and
                development work in support of IBM Power Systems and IBM z Systems in the area of high performance, reliability and power-aware 
                computer architectures. He holds a Ph.D. degree from University of Rochester.
                </p>
                <p>
                <b><a href="http://researcher.watson.ibm.com/researcher/view.php?person=us-pbose" rel="nofollow" target="_blank">Pradip 
                Bose</a> </b>is a Distinguished Research Staff Member and manager of <i>Efficient and Resilient Systems</i> at IBM T. J. 
                Watson Research Center. He has over thirty-three years of experience at IBM, and was a member of the pioneering RISC super 
                scalar project at IBM (a pre-cursor to the first RS/6000 system product). He holds a Ph.D. degree from University of Illinois 
                at Urbana-Champaign.
                </p>
                <p>
                <b><a href="https://www.linkedin.com/in/augusto-vega-5940684" rel="nofollow" target="_blank">Augusto Vega</a> </b>is a 
                Research Staff Member at IBM T. J. Watson Research Center involved in research and development work in the areas of 
                highly-reliable power-efficient embedded designs, cognitive systems and mobile computing. He holds a Ph.D. degree from 
                Polytechnic University of Catalonia (UPC), Spain.
                </p>
                <p>
                <b><a href="https://anands09.github.io" rel="nofollow" target="_blank">Ananda Samajdar</a> </b>is a Research Staff Member
				at IBM T. J. Watson Research Center working on accelerator design and compilation/mapping strategies for DNN workloads on
				IBM’s RaPiD AI accelerator. He holds a Ph.D. from Georgia Tech.
                </p>
                </div>
                <div id="contact" class="col-md-4">
                    <h4 class="section-title">Contact</h4>
                    <ul class="list-arrow-right">
                    <li><a href="mailto:info@cogarchworkshop.org">info@cogarchworkshop.org</a></li> 
                    </ul>
                </div>
            </div>
        </div>
    </section>

<!--
    <section id="facts" class="section bg-image-1 facts text-center">
        <div class="container">
            <div class="row">
                <div class="col-sm-6">

                    <i class="ion-earth"></i>
                    <h3><a href="http://researcher.watson.ibm.com/researcher/view_group_subpage.php?id=6586" rel="nofollow" target="_blank">CogArch 2015</a></h3>
                
                </div>
                <div class="col-sm-6">

                    <i class="ion-earth"></i>
                    <h3><a href="http://researcher.watson.ibm.com/researcher/view_group.php?id=5848" rel="nofollow" target="_blank">CogArch 2016</h3>
                
                </div>
            </div>
        </div>
    </section>
-->

    <section id="links" class="section bg-image-2 facts ">
        <div class="container">
            <div class="row">
				<div class="col-md-12">
                    <h3 class="section-title">Interesting Links</h3>
                </div>
				<div class="col-md-3">
                    <p>The <a href="http://www.computerhistory.org/timeline/ai-robotics/" target="_blank">AI and Robotics Timeline</a> from 1939 to date</p>
                </div>
				<div class="col-md-3">
                    <p>The <a href="http://research.ibm.com/cognitive-computing/" target="_blank">AI portal</a> with the latest research activities conducted by IBM on AI</p>
                </div>
				<div class="col-md-3">
                    <p>The <a href="https://research.ibm.com/topics/foundation-models" target="_blank">Foundation Models</a> portal</p>
                </div>
				<div class="col-md-3">
                    <p>IBM Watson in action in this <a href="https://www.ibm.com/demos/live/tts-demo/self-service/home" target="_blank">text-to-speech demo</a></p>
                </div>
          </div>
        </div>
    </section>


    <section id="location" class="section location">
        <div class="container">
            <div class="row">
			
				<div id="registration" class="col-md-3">
                    <h3 class="section-title">Registration</h3>

                    <p>
                    CogArch will be held in conjunction with the <b><a href="https://iscaconf.org/isca2023/"  target="_blank">
					50<sup>th</sup> International Symposium on Computer Architecture (ISCA 2023)</a></b>.
                    Refer to the main venue to continue with the registration process.
                    </p>
                </div>


                <div class="col-sm-3">
                    <h3 class="section-title">Event Location</h3>
                    <address>
					  <p>Orlando World Center Marriott<br>
					  8701 World Center Dr
					  Orlando, FL 32821
                      </p>
                    </address>
                    
                    <p><b><a href="https://iscaconf.org/isca2023/" target="_blank"> Check main venue site for more information.</a></b></p>

                </div>
                <div class="col-sm-6">
				  <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d224444.05442456398!2d-81.48274961435772!3d28.481403209853266!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x88e773d8fecdbc77%3A0xac3b2063ca5bf9e!2sOrlando%2C%20FL!5e0!3m2!1sen!2sus!4v1670867850436!5m2!1sen!2sus" width="600" height="450" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>
                </div>
            </div>
        </div>
    </section>


    <footer class="site-footer facts">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <p class="site-info">Share this event on your social networks</p>
                </div>
                <div class="col-md-4">
                    <a href="https://twitter.com/home?status=Check%20out%20the%20Workshop%20on%20Cognitive%20Architectures%0Ahttps%3A//cogarchworkshop.org"><i class="ion-social-twitter"></i>&nbsp; Twitter</a>
                </div>
                <div class="col-md-4">
                    <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//cogarchworkshop.org/"><i class="ion-social-facebook"></i>&nbsp; Facebook</a>
                </div>
                <div class="col-md-4">
                    <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A//cogarchworkshop.org/&title=Workshop%20on%20Cognitive%20Architectures&summary=&source="><i class="ion-social-linkedin-outline"></i>&nbsp; LinkedIn</a>
                </div>
            </div>
        </div>
    </footer>

    <!-- script -->
    <script src="bower_components/jquery/dist/jquery.min.js"></script>
    <script src="bower_components/bootstrap/dist/js/bootstrap.min.js"></script>
    <script src="bower_components/smooth-scroll/dist/js/smooth-scroll.min.js"></script>
    <script src="assets/js/main.js"></script>
</body>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-88908704-1', 'auto');
  ga('send', 'pageview');

</script>
  
</html>
